---
title: "Practica 1 DEX"
author: "Marta Venegas Pardo"
output: 
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
    toc: true
    toc_depth: 4
    number_section: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



Del tema 2.


# Ejemplo 1. Pollos

A cada animal le hemos observado dos cosas, la variable respuesta y los niveles del factor



```{r}
y<-c(100,115,95,99,105,115,98,97,93,95,98,105,105,110,94) # respuesta
 a<-c(rep(1,5),rep(2,5),rep(3,5)) # niveles del factor
 a<-factor(a) # hay que declararlo como factor, porque si no es una varaible numérica en R, cosa que no es
```


## Contraste

El contraste que vamos a realizar es el siguiente (pag5) apuntes:


$$
\left\{
\begin{array}{ll}
H_{0}: &  \alpha_1 = \alpha_2 = \alpha_3\\
H_{1}: & \alpha_i \neq \alpha_j \quad \text{para algunos } i\neq j
\end{array}
\right.
$$

## Tabla anova

```{r}
ejemplo1<-aov(y~a) # Análisis de la varianza = aov=(respuesta ~ factor)
 # N=15 , k=3
 summary(ejemplo1) # tabla de la varianza
```


- k=3
- N=15

Conclusiones: 


- Gr lib: k-1 = 2 
- Gr lib res_ N-k = 12
- $CM_{a}/CM_{r}$
- _p-valor_: RC=p-valor$ = 0.777 >  \alpha = 0.05$, luego, no hay evidencias en contra de $H_0$

Es decir, no existen evidencias para decir que las condiciones ambientales consideradas incidan en la ganancia de peso de los pollos.





Si a no es declarado factor, ocurriría un desastre. Haría el modelo lineal $y = \beta_0 + \beta_1 \cdot a + \epsilon$

```{r}
 a<-c(rep(1,5),rep(2,5),rep(3,5)) # niveles del factor

 ejemplo1.mal<-aov(y~a) # Análisis de la varianza = aov=(respuesta ~ factor)

 summary(ejemplo1.mal) # tabla de la varianza
```


Ahora estamos contrastando:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \beta_{1} = 0 \quad\\
H_{1}: & \beta_1 \neq 0
\end{array}
\right.
$$


## Estimadores

Estimadores de Míninos Cuadrados de los parámetros del modelo.

- Modelo: $y_{ij}= \mu + \alpha_i + \epsilon_{ij} \sim N(0,\sigma^2)$
- Parámetros: $\mu, \alpha_{i},\text{ con i = 1,2,3}, \sigma$

```{r}
summary(ejemplo1)
```

Ya tenemos el estimador de sigma 

$\hat\sigma = CM_{\epsilon} = 59.1$


Solución particular del SEN imponiendo: $\sum_{i=1}^k n_i \cdot \alpha_i = 0$



```{r}
# mu_gorro = media global
mu.gorro = mean(y)
mu.gorro
```

```{r}
# alpha.gorro_i = media de la población i-media global
alpha.gorro = tapply(y,a,mean)-mean(y)
```

Por tanto, tenemos que $\hat\alpha =$ `r alpha.gorro`





```{r}
str(ejemplo1)
```

La solución que R toma es la que se optiene al añadir al SEN $\alpha_1 = 0$

```{r}
ejemplo1$coefficients # mu gorro
```

Esta es la solución que da R, intercept es mu.gorro.

- estimador de alfa1 = 0 
- $\hat\alpha_1=0$
- a2 es el estimador de $\alpha_2$, $\hat\alpha_2= -3.2$
- a3 es el estimador de $\alpha3$, $\hat\alpha_3= -0.4$


Los de R se pueden obtener de los nuestros restandole 1.2 a cada uno de ellos.



# Ejemplo 2. Sucursales

## Contraste


```{r}
y<-c(10.3,10.9,10.4,12.8,11.0,10.6,9.8,12.0, 10.1,11.6,11.0,12.2,10.5,11.4,
9.9,13.0,10.6,11.0,10.0,12.7)
a<-rep(c(1:4),5)
a<-factor(a)
```

Realizamos el contraste:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \alpha_1 = \alpha_2 = \alpha_3 = \alpha_4\\
H_{1}: & \alpha_i \neq \alpha_j \quad \text{para algunos } i\neq j
\end{array}
\right.
$$

## Tabla ANOVA

```{r}
ejemplo2<-aov(y~a)
summary(ejemplo2)
```


- k=4
- N=20
- gr lib k-1 = 3 
- gr lib resíduos, gr lib del error N-k = 16
- p-valor enano, rechazo $H_0$, es decir, no tenemos evidencias para afirmar que las ganancias medias de las cuatro entidades bancarias sean iguales.

Conclusión:

Las 4 sucursales tienen una ganancia media distinta, nos interesa saber porque hemos rechazado. Aplicamos TECNICAS de comparaciones múltiples 

## Comparaciones múltiples


```{r}
library(agricolae)
```


### Mínima diferencia significativa (TEST LSD)

```{r}
#Test LSD
#LSD.test(respuesta,factor, gl del error, CM_e) =  LSD.test(respuesta,factor, N_k, CM_e)
#por defecto toma alpha=0.05. Si lo deseamos cambiar:
#LSD.test(respuesta,factor, gl del error, CM_e, alpha=0.01)
lsd<-LSD.test(y = y,trt = a,DFerror = 16,MSerror = 0.174)
lsd
```

LSD = 0.5592694, cantidad a partir de la cual considero dos medias distintas.


Observando la salida no se la intertpretacion, necesito mirarla. Vemos que la comparación correspondiente a las sucursales 1 y 3 es no significativa.


### Test Scheffé

```{r}
#Test Scheffe
#scheffe.test(respuesta,factor, gl del error, CM_e)
sch<-scheffe.test(y,a,16,0.174)
sch$groups
sch
```

Diferencia crítica. Un par de medias son consideradas significativamente distintas utilizando este método si en valor absoluto su diferencia es superior a esa cantidad.

Observamos: 

- No existen evidencias significativas en contra de que la ganancia media de las sucursales 1 y 2 sean diferentes.
- Tampoco existen evidencias significativas en contra de que la ganancia media de las sucursales 1 y 3 sean diferentes.
- **NOTA:** Esto no indica que la ganancia media de las sucursales 2 y 3 sean iguales, sólo que no existen evidencias en contra de que las otras, dos a dos, lo sean.


### Test de Tukey

```{r}
#Test Tukey
#HSD.test(respuesta,factor, gl del error, CM_e)
hsd<-HSD.test(y,a,16,0.174)
hsd$groups
hsd
```


- StudentizedRange: Punto crítico del recorrido studentizado
- MSD es el hsd

Misma conclusión que el test de Scheffé.


### Test de Newman-Keuls

```{r}
#Test Newman-Keuls
#SNK.test(respuesta,factor, gl del error, CM_e)
snk<-SNK.test(y,a,16,0.174)
snk$groups
snk
```


- Conclusión. Tres grupos no solapados de la siguiente forma:

        - Ganancias de la sucursal 4
        - Ganancias de la sucursal 2
        - Ganancias de las sucursales 1 y 3 (no podemos afirmar que sean significativamente distintas)



### Test de Duncan


```{r}
#Test Duncan
#duncan.test(respuesta,factor, gl del error, CM_e)
duncan<-duncan.test(y,a,16,0.174)
duncan$groups
```

Diferencia con el resto: también varía el alfa


```{r}
duncan
```

Esta tabla no está en clase. $ducan son los puntos críticos con la transformación del alfa. P criticos a partir de los cuales se rechaza cuando tenemos involucrada 2,3 y 4 medias.

Grupo: igual que antes.

### Método de Bonferroni

```{r}
#Bonferroni
#LSD.test(respuesta,factor, gl del error, CM_e, p.adj="bon")
bon<-LSD.test(y,a,16,0.174,p.adj="bon")
bon
```

MSD es corrección LSD. Coge la tstudent pero el alfa en vez de 1- alfa /2 es 1-alfa/2m. El p crítico es mayor. 
No es el mejor método si quiero comparar todas las medias. Misma solución que el de Tukey.


## Diagnosis

A partir de aov se pueden obtener los siguientes 4 gráficos:

### Normalidad

```{r}
#para que saque los 4 grficos en una pantalla
layout(matrix(c(1,2,3,4),ncol=2))
plot(ejemplo2)
```


- 1 _Hip. homocedasteceidad_: Si la hip fuera cierta, los datos tienen que estar en torno a una banda. Vemos la obs 11 del gr 1 un poco alejada pero no pasa nada, el resto estan en torno a una banda. La línea roja en torno a 0 es la que mejor ajuste a los datos (estimador núcleo, no lo he dado) Misma grafica q la 4, aqui ordenados por medias y allí por grupos.
- 2
- 3 _Normalidad_: EL títulito es para observaciones extremas. Los quantiles extremos tienen una mayor variabilidad. Las obs centrales se ajustan a una linea recta, lo que da indicativo a que los gráficos se ajustan a una ley normal
- 4

Puedo hacer el gráfico 3 por mi misma. Utilizando los resíduos que ya los tengo almacenados

```{r}
# str(ejemplo2) tenemos los resíduos
```


res = y- val ajustado

```{r}
par(mfrow=c(1,2))
qqnorm(ejemplo2$residuals) # grafico qq de normalidad
qqline(ejemplo2$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3



qqnorm(ejemplo2$residuals,
       main="Gráfico de normalidad" ) # grafico qq de normalidad
qqline(ejemplo2$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3
par(mfrow=c(1,1))
```
Esto es método gráfico. Un método formal es un test de hipótesis.

```{r}
library(nortest)
#Test de CvM  para contrastar normalidad: hay que cargar el paquete nortest
cvm.test(ejemplo2$residuals) # le quiero aplicar el test a los resíduos
```

Conclusión, por tanto: el p-vlaor es mayor que alfa. No hay evidencias para rechazar la hipótesis nula. $H_0: \epsilon ~ N(0,\sigma^2)$, para algun $\sigma^2>0$.


### Independencia

A modo de ejercicio, en este problema no tiene sentido, porque no sabemos el orden en el que fueron obtenidas las observaciones.

Vamos a suponer que los datos del vector y han sido copiados en el mismo orden que fueron obtenidos los datos



```{r}
layout(matrix(c(1,2,3),ncol=3))
plot(c(1:20),ejemplo2$residuals, type="p") #dibuja puntos
plot(c(1:20),ejemplo2$residuals, type="l") #dibuja lineas uniendo los puntos
plot(c(1:20),ejemplo2$residuals, type="b", xlab="tiempo", ylab="resíduos") #ambos
abline(h=0) #a\~nade a grafico al linea h=0
```


No se observa patron, podemos decir que existe independencia del tiempo.


### Homocedasteceidad


Gráfico de resíduos frente a medias



```{r}
plot(ejemplo2$fitted.values, ejemplo2$residuals, xlab="medias", ylab="residuos")
abline(h=0) #a\~nade a grafico al linea h=0
```


```{r}
#  residuos vs grupos
#  primero hay que convertir a en numerico, en cc representa el box-plot de cada grupo
a<-as.numeric(a)
plot(a, ejemplo2$residuals, xlab="grupos", ylab="residuos")
abline(h=0) #añade al grafico al linea h=0
```








```{r}
library(lawstat)
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a) # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```





Errata en los apuntes, en la página 14, aparece en el test de barlett un 2.pico multiplicando al cociente de la chicuadrado. Ese 2 hay que tacharlo, porque es cuadno el log es en base 10. Nosotros siempre tomamos neperiano, por lo que no necesitamos eso.




```{r}
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a, location = "mean") # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


```{r}
a<-factor(a)
ares<-abs(ejemplo2$residuals)
summary(aov(ares~a))
```


```{r}
#Test de Bartlett
bartlett.test(y,a)
```






# Ejercicio 1 

Se está realizando un estudio sobre el tiempo de respuesta (medido en milisegundos) de tres tipos diferentes de circuitos que serán utilizados en la construcción de una calculadora. 
Los resultados son:


```{r}
y<-c(9,12,10,8,15,
     20,21,23,17,30,
     6,5,8,16,7)
a<-rep(c(1:3),5)
a<-factor(a)
matrix(y,byrow = TRUE,nrow = 3)
```


## Contraste




Realizamos el contraste:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \alpha_1 = \alpha_2 = \alpha_3 \\
H_{1}: & \alpha_i \neq \alpha_j \quad \text{para algunos } i\neq j
\end{array}
\right.
$$

## Tabla ANOVA

```{r}
ejercicio1<-aov(y~a)
summary(ejercicio1)
```


- k=3
- N=15
- gr lib k-1 = 2
- gr lib resíduos, gr lib del error N-k = 12
- p-valor=$0.771>|alpha=0.05$, no tengo evidencias en contra de $H_0$, es decir, no tenemos evidencias para afirmar que los tiempos de respuesta sean diferentes en cada circuito.

Conclusión:

Los tres tipos de circuito tienen un tiempo de respuesta medio similar.

# Ejercicio 2


En un laboratorio se estudian cuatro catalizadores que pueden afectar a la concentración de uno de los elementos de una mezcla. Los resultados del estudio se muestran en la siguiente tabla:


```{r}
y<-c(
        58.2, 57.2,  58.4 , 55.8,54.9,
        56.3 ,54.5 , 57.0 , 55.3,
        50.1, 54.2 , 55.4 ,
        52.9 ,49.9 ,50.0 ,51.7
)

a<-c(rep(1,5),
     rep(2,4),
     rep(3,3),
     rep(4,4))
a<-factor(a)
```

## Estimar los parámetros del modelo

### Tabla anova


```{r}
ejercicio2<-aov(y~a) # Análisis de la varianza = aov=(respuesta ~ factor)
 # N=15 , k=3
summary(ejercicio2) # tabla de la varianza
```

- $\hat\sigma=CM_\epsilon = 2.88$

Para calcular $\hat\alpha$, calculamos el estimador de la media $\hat\mu$

```{r}
mu.gorro = mean(y)

alpha.gorro = tapply(y, a, mean)- mu.gorro
```


Por tanto, tenemos que $\hat\alpha =$ `r alpha.gorro`

La solución que da R es la que se optiene a partir de añadir al sen que $\alpha_1=0$

```{r}
ejercicio2$coefficients # mu gorro
```


Esta es la solución que da R, intercept es mu.gorro.

- estimador de alfa1 = 0 
- $\hat\alpha_1=0$
- a2 es el estimador de $\alpha_2$, $\hat\alpha_2= -1.125$
- a3 es el estimador de $\alpha3$, $\hat\alpha_3= -3.667$
- a4 es el estimador de $\alpha4$, $\hat\alpha_4= -5.775$




## Diagnosis, ya que existen resultados raritos


A partir de aov se pueden obtener los siguientes 4 gráficos:

### Normalidad

```{r}
#para que saque los 4 grficos en una pantalla
layout(matrix(c(1,2,3,4),ncol=2))
plot(ejercicio2)
```


- 1 _Hip. homocedasteceidad_: Si la hip fuera cierta, los datos tienen que estar en torno a una banda. Vemos la obs 11 del gr 1 un poco alejada pero no pasa nada, el resto estan en torno a una banda. La línea roja en torno a 0 es la que mejor ajuste a los datos (estimador núcleo, no lo he dado) Misma grafica q la 4, aqui ordenados por medias y allí por grupos.
- 2
- 3 _Normalidad_: EL títulito es para observaciones extremas. Los quantiles extremos tienen una mayor variabilidad. Las obs centrales se ajustan a una linea recta, lo que da indicativo a que los gráficos se ajustan a una ley normal
- 4

Puedo hacer el gráfico 3 por mi misma. Utilizando los resíduos que ya los tengo almacenados

```{r}
# str(ejemplo2) tenemos los resíduos
```


res = y- val ajustado

```{r}
par(mfrow=c(1,2))
qqnorm(ejercicio2$residuals) # grafico qq de normalidad
qqline(ejercicio2$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3



qqnorm(ejercicio2$residuals,
       main="Gráfico de normalidad" ) # grafico qq de normalidad
qqline(ejercicio2$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3
par(mfrow=c(1,1))
```
Esto es método gráfico. Un método formal es un test de hipótesis.

```{r}
library(nortest)
#Test de CvM  para contrastar normalidad: hay que cargar el paquete nortest
cvm.test(ejercicio2$residuals) # le quiero aplicar el test a los resíduos
```

Conclusión, por tanto: el p-vlaor es mayor que alfa. No hay evidencias para rechazar la hipótesis nula. $H_0: \epsilon ~ N(0,\sigma^2)$, para algun $\sigma^2>0$.


### Independencia

A modo de ejercicio, en este problema no tiene sentido, porque no sabemos el orden en el que fueron obtenidas las observaciones.

Vamos a suponer que los datos del vector y han sido copiados en el mismo orden que fueron obtenidos los datos



```{r}
layout(matrix(c(1,2,3),ncol=3))
plot(c(1:16),ejercicio2$residuals, type="p") #dibuja puntos
plot(c(1:16),ejercicio2$residuals, type="l") #dibuja lineas uniendo los puntos
plot(c(1:16),ejercicio2$residuals, type="b", xlab="tiempo", ylab="resíduos") #ambos
abline(h=0) #a\~nade a grafico al linea h=0
```


No se observa patron, podemos decir que existe independencia del nivel de concentración.


### Homocedasteceidad


Gráfico de resíduos frente a medias



```{r}
plot(ejercicio2$fitted.values, ejercicio2$residuals, xlab="medias", ylab="residuos")
abline(h=0) #a\~nade a grafico al linea h=0
```


```{r}
#  residuos vs grupos
#  primero hay que convertir a en numerico, en cc representa el box-plot de cada grupo
a<-as.numeric(a)
plot(a, ejercicio2$residuals, xlab="grupos", ylab="residuos")
abline(h=0) #añade al grafico al linea h=0
```








```{r}
library(lawstat)
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a) # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


- p-valor $= 0.74 > \alpha =0.05$, no rechazo $H_0$, hipótesis de homocedasteceidad.




```{r}
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a, location = "mean") # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


```{r}
a<-factor(a)
ares<-abs(ejercicio2$residuals)
summary(aov(ares~a))
```


```{r}
#Test de Bartlett
bartlett.test(y,a)
```











## ¿Tienen los cuatro catalizadores el mismo efecto sobre la concentración?



```{r}
summary(ejercicio2) # tabla de la varianza
```

- P-valor = $0.00144 < \alpha = 0.05$, rechazo $H_0$, no tengo evidencias afirmar que los cuatro catalizadores tengan el mismo efecto sobre la concentración.

## Intervalo de confianza para el efecto medio del primer catalizador



## Si existiesen diferencias entre los efectos, estudie cuáles pueden ser los motivos de tales diferencias (comparaciones múltiples)




### Test de Tukey

```{r}
#Test Tukey
#HSD.test(respuesta,factor, gl del error, CM_e)
hsd<-HSD.test(y,a,12,2.88,unbalanced = TRUE)
hsd$groups
hsd
```


- StudentizedRange: Punto crítico del recorrido studentizado
- MSD es el hsd

Misma conclusión que el test de Scheffé.


### Test de Newman-Keuls

```{r}
#Test Newman-Keuls
#SNK.test(respuesta,factor, gl del error, CM_e)
snk<-SNK.test(y,a,12,2.88)
snk$groups
snk
```


- Conclusión. Tres grupos no solapados de la siguiente forma:

        - Concentración de los catalizadores 1 y 2 
        - Concentración de los catalizadores 2 y 3 
        - Concentración de los catalizadores 4 y 3 

No podemos afirmar que sean significativamente distintas


### Test de Duncan


```{r}
#Test Duncan
#duncan.test(respuesta,factor, gl del error, CM_e)
duncan<-duncan.test(y,a,12,2.88)
duncan$groups
```

Diferencia con el resto: también varía el alfa


        - Concentración de los catalizadores 1 y 2 
        - Concentración de los catalizadores 2 y 3 
        - Concentración de los catalizadores 4 y 3 


```{r}
duncan
```

Esta tabla no está en clase. $ducan son los puntos críticos con la transformación del alfa. P criticos a partir de los cuales se rechaza cuando tenemos involucrada 2,3 y 4 medias.

Grupo: igual que antes.

### Método de Bonferroni

```{r}
#Bonferroni
#LSD.test(respuesta,factor, gl del error, CM_e, p.adj="bon")
bon<-LSD.test(y,a,12,2.88,p.adj="bon")
bon
```

MSD es corrección LSD. Coge la tstudent pero el alfa en vez de 1- alfa /2 es 1-alfa/2m. El p crítico es mayor. 
No es el mejor método si quiero comparar todas las medias.

Grupos:

- Catalizadores 1,2,3
- Catalizadores 3 y 4















# Ejercicio 3

```{r}
y<-c(133.8,125.3,143.1 ,128.9, 135.7 ,
     152.2 ,149.0 ,162.7 ,145.8 ,153.5 ,
      225.8 ,224.6, 220.4 ,212.3 ,
      193.4 ,185.3, 182.8 ,188.5 ,198.6 )
# el diseño no es balanceado
a<-c(rep(1,5),
     rep(2,5),
     rep(3,4),
     rep(4,5))
a<-factor(a)
```



## Tabla anova
```{r}
Anova3<-aov(y~a)
summary(Anova3)
```


- Rechazo H0: No tengo evidencias para afirmar que las cuatro dietas funcionan igual (misma efectividad) de cara al crecimiento de los cerdos
- $SC_\epsilon = 41$



## Comparaciones múltiples

### Test LSD
```{r}
hsd <- HSD.test(y,a,15,41,unbalanced = TRUE)
hsd
```

Rechazo porque hay 4 grupos distintos, las 4 dietas son diferentes.

### Test de Tukey

```{r}
#Test Tukey
#HSD.test(respuesta,factor, gl del error, CM_e)
hsd<-HSD.test(y,a,15,41,unbalanced = TRUE)
hsd$groups
```




## Diagnosis 



### Normalidad

#### Gráfico

```{r}
layout(matrix(c(1,2,3,4),ncol=2))
plot(Anova3)
```


Gráficamente observando el QQ plot parece que voy a aceptar la normalidad, los puntos están alrededor de una linea recta, con más enfasis en el centro existen oscilaciones en los extremos

```{r}
qqnorm(Anova3$residuals) # grafico qq de normalidad
qqline(Anova3$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3
```


#### Test de CvM  para contrastar normalidad

Test: H0: $\epsilon \sim  N(0,\sigma^2), \quad \text{con } \sigma^2 > 0$


```{r}
cvm.test(Anova3$residuals)
```

No existen evidencias para decir que los errores no se distribuyen segun una ley normal


### Independencia

No tiene sentido aquí, ya que no puedo saber cuadno he observado las respuestas




### Homocedasteceidad

#### Método gráfico


```{r}
# residuos vs valores ajustados
plot(Anova3$fitted.values, Anova3$residuals, xlab="medias", ylab="residuos")
abline(h=0) #añade a grafico al linea h=0
```


Datos en torno a una banda, no se observa que la oscilación cambie con el valor de los fitted values, parece por el gráfico que no voy a rechazar la homocedasteceidad el gráfico me ayuda a saber el porque rechazo

```{r}
#  residuos vs grupos
a<-as.numeric(a)
plot(a, Anova3$residuals, xlab="grupos", ylab="residuos")
abline(h=0) #añade al grafico al linea h=0
```



#### Test

```{r}
#Test de Levene: hay que cargar el paquete lawstat
library(lawstat)
levene.test(y,a,location = "mean") # deviations from the median
# Nota: si hay outliers el p-valor habría cambiado considerablemente al poner mean
```


No existen evidencias en contra de la hipótesis homocedastecerdad, por tanto, las varianzas son iguales.


```{r}
#Test de Bartlett
bartlett.test(y,a)

```


Misma conclusión con este test




# Ejercicio 4


## Contraste


```{r}
y<-c(
     7 ,7  ,15 ,11, 9,
     12,17 ,12 ,18, 18 ,
     14,18 ,19 ,19,  19,
     19,25 ,22 ,19, 23 ,
     7 ,10 ,11 ,15, 11
)
a<-c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5))
a<-factor(a)
```

Realizamos el contraste:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \alpha_1 = \alpha_2 = \alpha_3 = \alpha_4\\
H_{1}: & \alpha_i \neq \alpha_j \quad \text{para algunos } i\neq j
\end{array}
\right.
$$

## Tabla ANOVA

```{r}
ejercicio4<-aov(y~a)
summary(ejercicio4)
```


- k=5
- N=25
- gr lib k-1 = 4 
- gr lib resíduos, gr lib del error N-k = 20
- p-valor enano, no tengo evidencias significativas para afirmar que la resistencia media de los tejidos es la misma.

## Comparaciones múltiples







### Test de Tukey

```{r}
#Test Tukey
#HSD.test(respuesta,factor, gl del error, CM_e)
hsd<-HSD.test(y,a,20,8.14)
hsd$groups
hsd
```


- StudentizedRange: Punto crítico del recorrido studentizado = 4.23
- MSD es el hsd = 5.399

Grupos:

- Tejido 4 y 3
- Tejido 3 y 2
- Tejido 2 y 5 
- Tejido 5 y 1

Para el desempate: teste de N-K


### Test de Newman-Keuls

```{r}
#Test Newman-Keuls
#SNK.test(respuesta,factor, gl del error, CM_e)
snk<-SNK.test(y,a,20,8.14)
snk$groups
```

Conclusión: tengo tres grupos de tejidos con resistencia significativamente similar

- Tejido 4 
- Tejidos 3 y 2 
- Tejidos 5 y 1


```{r}
snk
```

Nota: Por tanto, hemos rechazado porque existen tres grupos diferentes de resistencia de tejidos.



## Diagnosis

A partir de aov se pueden obtener los siguientes 4 gráficos:

### Normalidad

```{r}
#para que saque los 4 grficos en una pantalla
layout(matrix(c(1,2,3,4),ncol=2))
plot(ejercicio4)
```


- 1 _Hip. homocedasteceidad_: Si la hip fuera cierta, los datos tienen que estar en torno a una banda. Vemos la obs 11 del gr 1 un poco alejada pero no pasa nada, el resto estan en torno a una banda. La línea roja en torno a 0 es la que mejor ajuste a los datos (estimador núcleo, no lo he dado) Misma grafica q la 4, aqui ordenados por medias y allí por grupos.
- 2
- 3 _Normalidad_: EL títulito es para observaciones extremas. Los quantiles extremos tienen una mayor variabilidad. Las obs centrales se ajustan a una linea recta, lo que da indicativo a que los gráficos se ajustan a una ley normal
- 4

Puedo hacer el gráfico 3 por mi misma. Utilizando los resíduos que ya los tengo almacenados

```{r}
# str(ejemplo2) tenemos los resíduos
```


res = y- val ajustado

```{r}
par(mfrow=c(1,2))
qqnorm(ejercicio4$residuals) # grafico qq de normalidad
qqline(ejercicio4$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3



qqnorm(ejercicio4$residuals,
       main="Gráfico de normalidad" ) # grafico qq de normalidad
qqline(ejercicio4$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3
par(mfrow=c(1,1))
```
Esto es método gráfico. Un método formal es un test de hipótesis.

```{r}
library(nortest)
#Test de CvM  para contrastar normalidad: hay que cargar el paquete nortest
cvm.test(ejercicio4$residuals) # le quiero aplicar el test a los resíduos
```

Conclusión, por tanto: el p-valor es mayor que alfa. No hay evidencias para rechazar la hipótesis nula. $H_0: \epsilon ~ N(0,\sigma^2)$, para algun $\sigma^2>0$.


### Independencia

A modo de ejercicio, en este problema no tiene sentido, porque no sabemos el orden en el que fueron obtenidas las observaciones.

Vamos a suponer que los datos del vector y han sido copiados en el mismo orden que fueron obtenidos los datos



```{r}
layout(matrix(c(1,2,3),ncol=3))
plot(c(1:25),ejercicio4$residuals, type="p") #dibuja puntos
plot(c(1:25),ejercicio4$residuals, type="l") #dibuja lineas uniendo los puntos
plot(c(1:25),ejercicio4$residuals, type="b", xlab="tiempo", ylab="resíduos") #ambos
abline(h=0) #a\~nade a grafico al linea h=0
```


No se observa patron, podemos decir que existe independencia del tiempo.


### Homocedasteceidad


Gráfico de resíduos frente a medias



```{r}
plot(ejercicio4$fitted.values, ejercicio4$residuals, xlab="medias", ylab="residuos")
abline(h=0) #a\~nade a grafico al linea h=0
```


```{r}
#  residuos vs grupos
#  primero hay que convertir a en numerico, en cc representa el box-plot de cada grupo
a<-as.numeric(a)
plot(a, ejercicio4$residuals, xlab="grupos", ylab="residuos")
abline(h=0) #añade al grafico al linea h=0
```








```{r}
library(lawstat)
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a) # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


P-valor mayor que alpha, no existen evidencias en contra de la hipótesis de homocedasteceidad


Errata en los apuntes, en la página 14, aparece en el test de barlett un 2.pico multiplicando al cociente de la chicuadrado. Ese 2 hay que tacharlo, porque es cuadno el log es en base 10. Nosotros siempre tomamos neperiano, por lo que no necesitamos eso.




```{r}
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a, location = "mean") # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


```{r}
a<-factor(a)
ares<-abs(ejercicio4$residuals)
summary(aov(ares~a))
```


```{r}
#Test de Bartlett
bartlett.test(y,a)
```











# Ejercicio 5
Los datos han sido obtenidos bajo cuatro condiciones, se desea averiguar si las condiciones consideradas inciden en la respuesta media.



## Contraste


```{r}
y<-c(39 ,40 ,42 ,37 ,40 ,40 ,38 ,39 ,41 ,38,
 34 ,34 ,34 ,34 ,35 ,35 ,34 ,35 ,34 ,34,
 41 ,39 ,41 ,41 ,41 ,40 ,40 ,41 ,41 ,41,
 37 ,37 ,36 ,36 ,38 ,37 ,39 ,36 ,36 ,38)

  

a<-c(rep(1,10),rep(2,10),rep(3,10),rep(4,10))
a<-factor(a)
```

Realizamos el contraste:

$$
\left\{
\begin{array}{ll}
H_{0}: &  \alpha_1 = \alpha_2 = \alpha_3 = \alpha_4\\
H_{1}: & \alpha_i \neq \alpha_j \quad \text{para algunos } i\neq j
\end{array}
\right.
$$

## Tabla ANOVA

```{r}
ejercicio5<-aov(y~a)
summary(ejercicio5)
```


- k=4
- N=40
- gr lib k-1 = 3 
- gr lib resíduos, gr lib del error N-k = 36
- p-valor enano, no tengo evidencias significativas para afirmar que la resistencia media de los tejidos es la misma.
- $\hat\alpha=CM_\epsilon=1.02$

## Comparaciones múltiples


### Test de Tukey

```{r}
#Test Tukey
#HSD.test(respuesta,factor, gl del error, CM_e)
hsd<-HSD.test(y,a,36,1.02)
hsd$groups
hsd
```


- StudentizedRange: Punto crítico del recorrido studentizado = 3.808798
- MSD es el hsd = 1.21

Grupos:

- Condición 3 y 1
- Condición 4
- Condición 2

Para el desempate: teste de N-K


### Test de Newman-Keuls

```{r}
#Test Newman-Keuls
#SNK.test(respuesta,factor, gl del error, CM_e)
snk<-SNK.test(y,a,36,1.02)
snk$groups
```

Conclusión: tengo cuatro grupo de condiciones diferentes con respuesta media diferente



```{r}
snk
```

Nota: Por tanto, hemos rechazado porque existen cuatro grupos diferentes de resistencia de tejidos.



## Diagnosis

A partir de aov se pueden obtener los siguientes 4 gráficos:

### Normalidad

```{r}
#para que saque los 4 grficos en una pantalla
layout(matrix(c(1,2,3,4),ncol=2))
plot(ejercicio5)
```


- 1 _Hip. homocedasteceidad_: Si la hip fuera cierta, los datos tienen que estar en torno a una banda. Vemos la obs 11 del gr 1 un poco alejada pero no pasa nada, el resto estan en torno a una banda. La línea roja en torno a 0 es la que mejor ajuste a los datos (estimador núcleo, no lo he dado) Misma grafica q la 4, aqui ordenados por medias y allí por grupos.
- 2
- 3 _Normalidad_: EL títulito es para observaciones extremas. Los quantiles extremos tienen una mayor variabilidad. Las obs centrales se ajustan a una linea recta, lo que da indicativo a que los gráficos se ajustan a una ley normal
- 4

Puedo hacer el gráfico 3 por mi misma. Utilizando los resíduos que ya los tengo almacenados

```{r}
# str(ejemplo2) tenemos los resíduos
```


res = y- val ajustado

```{r}
par(mfrow=c(1,2))
qqnorm(ejercicio5$residuals) # grafico qq de normalidad
qqline(ejercicio5$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3



qqnorm(ejercicio5$residuals,
       main="Gráfico de normalidad" ) # grafico qq de normalidad
qqline(ejercicio5$residuals) # grafico qq de normalidad + linea pasando por Q1 y Q3
par(mfrow=c(1,1))
```
Esto es método gráfico. Un método formal es un test de hipótesis.

```{r}
#Test de CvM  para contrastar normalidad: hay que cargar el paquete nortest
cvm.test(ejercicio5$residuals) # le quiero aplicar el test a los resíduos
```

Conclusión, por tanto: el p-valor es mayor que alfa. No hay evidencias para rechazar la hipótesis nula. $H_0: \epsilon ~ N(0,\sigma^2)$, para algún $\sigma^2>0$.


### Independencia

A modo de ejercicio, en este problema no tiene sentido, porque no sabemos el orden en el que fueron obtenidas las observaciones.

Vamos a suponer que los datos del vector y han sido copiados en el mismo orden que fueron obtenidos los datos



```{r}
layout(matrix(c(1,2,3),ncol=3))
plot(c(1:40),ejercicio5$residuals, type="p") #dibuja puntos
plot(c(1:40),ejercicio5$residuals, type="l") #dibuja lineas uniendo los puntos
plot(c(1:40),ejercicio5$residuals, type="b", xlab="tiempo", ylab="resíduos") #ambos
abline(h=0) #a\~nade a grafico al linea h=0
```


No se observa patron, podemos decir que existe independencia del tiempo.


### Homocedasteceidad


Gráfico de resíduos frente a medias



```{r}
plot(ejercicio5$fitted.values, ejercicio5$residuals, xlab="medias", ylab="residuos")
abline(h=0) #a\~nade a grafico al linea h=0
```


```{r}
#  residuos vs grupos
#  primero hay que convertir a en numerico, en cc representa el box-plot de cada grupo
a<-as.numeric(a)
plot(a, ejercicio5$residuals, xlab="grupos", ylab="residuos")
abline(h=0) #añade al grafico al linea h=0
```








```{r}
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a) # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


P-valor menor que alpha, no existen evidencias a favor de la hipótesis de homocedasteceidad.






```{r}
#Test de Levene: hay que cargar el paquete lawstat
levene.test(y,a, location = "mean") # por defecto resta la mediana, en clase lo hicimos con la media y por eso no coincide
```


```{r}
a<-factor(a)
ares<-abs(ejercicio5$residuals)
summary(aov(ares~a))
```


```{r}
#Test de Bartlett
bartlett.test(y,a)
```


No existe homocedasteceidad.





